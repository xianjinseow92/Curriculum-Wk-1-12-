{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro-to-Keras\" data-toc-modified-id=\"Intro-to-Keras-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro to <code>Keras</code></a></span></li><li><span><a href=\"#Installing-Keras\" data-toc-modified-id=\"Installing-Keras-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Installing <code>Keras</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-the-GPU\" data-toc-modified-id=\"Using-the-GPU-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Using the GPU</a></span></li></ul></li><li><span><a href=\"#Building-Keras-Models-:-ANN-Example\" data-toc-modified-id=\"Building-Keras-Models-:-ANN-Example-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Building <code>Keras</code> Models : ANN Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Sequential-API\" data-toc-modified-id=\"The-Sequential-API-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>The Sequential API</a></span></li><li><span><a href=\"#The-Functional-API\" data-toc-modified-id=\"The-Functional-API-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>The Functional API</a></span></li></ul></li><li><span><a href=\"#Training-Keras-Models\" data-toc-modified-id=\"Training-Keras-Models-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Training <code>Keras</code> Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Compiling-the-Network\" data-toc-modified-id=\"Compiling-the-Network-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Compiling the Network</a></span></li><li><span><a href=\"#Training-the-Network\" data-toc-modified-id=\"Training-the-Network-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Training the Network</a></span></li><li><span><a href=\"#Evaluating-and-Making-Predictions\" data-toc-modified-id=\"Evaluating-and-Making-Predictions-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Evaluating and Making Predictions</a></span></li></ul></li><li><span><a href=\"#Advanced-Keras-Layers\" data-toc-modified-id=\"Advanced-Keras-Layers-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Advanced <code>Keras</code> Layers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dropout-Layers\" data-toc-modified-id=\"Dropout-Layers-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Dropout Layers</a></span></li><li><span><a href=\"#Merge-Layers\" data-toc-modified-id=\"Merge-Layers-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Merge Layers</a></span></li><li><span><a href=\"#And-More...\" data-toc-modified-id=\"And-More...-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>And More...</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:37.709585Z",
     "start_time": "2019-05-31T22:25:33.825168Z"
    },
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Basics\n",
    "#import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "#from keras.layers import Concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "np.random.seed(13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intro to `Keras` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Installing `Keras`\n",
    "\n",
    "You should already have keras installed. But if you ever need to re-install (in a new conda environment, for example), run this at the command line:\n",
    "\n",
    "```$ conda install -c conda-forge keras```\n",
    "\n",
    "If that doesn't work:\n",
    "\n",
    "```$ conda install tensorflow```\n",
    "\n",
    "... move into a folder for installing tools\n",
    "\n",
    "```$ git clone https://github.com/fchollet/keras.git```\n",
    "\n",
    "```$ cd keras```\n",
    "\n",
    "```$ python setup.py install```\n",
    "\n",
    "You can run this on your laptop, but it will be very slow. If you have a CUDA 7.5 compatable GPU (or use an AWS instance with one) keras will run way faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the GPU\n",
    "\n",
    "Deep Learning requires tons of matrix computations. GPUs can do this really fast in parallel (many cores!)\n",
    "\n",
    "If you're working on a computer with a GPU and want to configure it for keras:\n",
    "  - Install [CUDA](http://docs.nvidia.com/cuda/index.html#axzz4Pa5zY8Qi) \n",
    "  - In `.bashrc`/`.bash_profile`: `export THEANO_FLAGS=device=gpu,floatX=float32`\n",
    "\n",
    "But if not, don't worry, you can just use AWS's big toys! **When using AWS, a Deep Learning AMI is highly recommended**-- use an AMI to get all the packages you need (including CUDA setup) handled up front. We'll walk through these steps in another notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building `Keras` Models : ANN Example\n",
    "The core objects in `Keras` are `Models` and `Layers`\n",
    "- `Models` set up the container for your network\n",
    "- `Layers` fill in the architecture (connections, unit types, activation functions, etc)\n",
    "- The 2 options for `Models`:\n",
    "  - `Sequential`: The basic one we'll focus on\n",
    "  - Function API: Specify more complex models, more flexibility\n",
    "- There are lots of options for types of `Layers`. We'll start with two familiar ones:\n",
    "  - `Dense` layers are fully connected, meaning every node receives a linear combination of each node in its input layer.\n",
    "  - `Activation` layers apply an activation function to the value of each node in the previous layer.\n",
    "  - Alternatively, Dense layers may be created with an activation function as a parameter.\n",
    "  \n",
    "We'll look at how to build an ANN (Artificial Neural Network) using both the Sequential and Functional APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Sequential API\n",
    "\n",
    "Sequential Model is like a Sklearn object with extra features. Most importantly, it is an empty container that allows you to design whatever architecture you want (i.e., by adding `Layers`).\n",
    "\n",
    "Let's start filling it with layers. We can specify all of them at the time we create the model, or we can just create an empty container and add layers to it. Each method produces the same model, but the second one can be used to build models programatically, if you're interested in going that route.\n",
    "\n",
    "(See the [Keras Documentation on the Sequential API](https://keras.io/getting-started/sequential-model-guide/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:40.564438Z",
     "start_time": "2019-05-31T22:25:40.485943Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Sequential model, all layers added at initialization\n",
    "model1 = Sequential([\n",
    "    Dense(32, input_dim=784),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:41.252749Z",
     "start_time": "2019-05-31T22:25:41.196491Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Sequential model, empty at initialization, layers added later.\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(32, input_dim=784)) # \n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Functional API\n",
    "\n",
    "The Functional API is a different approach to building models in keras. Each layer in a network is defined as a function that takes the previous layer as an input. Then the model is created by taking the input and output layers as parameters. \n",
    "\n",
    "Choosing between the Sequential and Functional APIs is usually a matter of personal preference, although there are some architectures that cannot be created using the Sequential API (notably siamese networks, in which a Merge layer combines the inputs from two paths of layers).\n",
    "\n",
    "(See the [Keras Documentation on the Functional API](https://keras.io/getting-started/functional-api-guide/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:42.199690Z",
     "start_time": "2019-05-31T22:25:42.147461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same as the Sequential models, but needs an explicit Input layer.\n",
    "# Note that each layer uses the same classes we used to create layers for our Sequential models,\n",
    "# but the layers are connected by passing them as parameters in layer function calls.\n",
    "# The model itself takes only the input and output layers as parameters.\n",
    "\n",
    "input_layer = Input(shape=(784,))\n",
    "hidden_layer = Dense(32)(input_layer)\n",
    "hidden_act = Activation('relu')(hidden_layer)\n",
    "output_layer = Dense(10)(hidden_act)\n",
    "output_act = Activation('softmax')(output_layer)\n",
    "\n",
    "model3 = Model(inputs=input_layer, outputs=output_act)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:42.812860Z",
     "start_time": "2019-05-31T22:25:42.751957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Activations do not need to be included as separate layers.\n",
    "\n",
    "input_layer = Input(shape=(784,))\n",
    "hidden_layer = Dense(32, activation='relu')(input_layer)\n",
    "output_layer = Dense(10, activation='softmax')(hidden_layer)\n",
    "\n",
    "model4 = Model(inputs=input_layer, outputs=output_layer)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the summary printouts, these three models have the same architecture. The models built with the Functional API do have the benefit of having the Input dimensions included in the summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training `Keras` Models\n",
    "\n",
    "Sequential models and Models built with the functional API behave similarly, but there are some subtle differences. \n",
    "\n",
    "See the [Keras Models Documentation](https://keras.io/models/about-keras-models/) if you ever get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compiling the Network\n",
    "\n",
    "The `Model.compile()` function configures a model for training. In order to do this, we need to specify the loss function, the optimizer algorithm, and the metrics we wish to use to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:25:45.207781Z",
     "start_time": "2019-05-31T22:25:45.143235Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the network\n",
    "model4.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training the Network\n",
    "\n",
    "Similar to `sklearn`, we can train keras models by calling `fit` on `numpy` arrays.\n",
    "\n",
    "We can specify minibatch learning using the `epochs` and `batch_size` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:26:18.389978Z",
     "start_time": "2019-05-31T22:25:45.890395Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1,784)/255 # reshape from 28x28 to 784 and\n",
    "X_test = X_test.reshape(-1,784)/255   # rescale from [0,255] to [0,1]\n",
    "\n",
    "# Fit the model \n",
    "model4.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating and Making Predictions\n",
    "\n",
    "Trained keras models have an `evaluate` method that returns the loss values and metrics values for the model in test mode. They also have a `predict` method for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:26:19.016762Z",
     "start_time": "2019-05-31T22:26:18.397079Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "loss_and_metrics = model4.evaluate(X_test, y_test, batch_size=32)\n",
    "print('\\nLoss and Accuracy:\\n', loss_and_metrics)\n",
    "\n",
    "# Make Predictions\n",
    "classes = model4.predict(X_test, batch_size=32)\n",
    "#proba = model4.predict_proba(X_test, batch_size=32)\n",
    "print('\\nClass Predictions:\\n', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... probably not a model we'll want to put into production, but at least we're able to train it and make predictions. \n",
    "\n",
    "How would you go about building new architectures to train and compare performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced `Keras` Layers\n",
    "\n",
    "- Layers define:\n",
    "  - Nodes (number of features in a layer, and how they are connected to nodes in the previous layer)\n",
    "  - Activations (transformations applied to the data coming into a node from other nodes it is connected to) \n",
    "  - Other Properties (for example, reshaping the feature arrays, dropout, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dropout Layers\n",
    "\n",
    "**Dropout** is a regularization technique used to control overfitting in neural networks. Instead of adding a penalty to our Loss function, Dropout works by randomly setting some proportion of the weights between layers to zero. This prevents the layer from relying too heavily on any of its inputs.\n",
    "\n",
    "Here is an example of Dropout being used in an ANN that classifies documents from the Reuters newsgroups data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:26:45.142424Z",
     "start_time": "2019-05-31T22:26:19.021153Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Set the max number of words to keep, 2000 most frequent \n",
    "max_features = 2000\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=max_features)\n",
    "maxlen = 10\n",
    "\n",
    "# Data is stored in sentences, pad any that are shorter than 10 words with zeros\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# The 'kernel_initializer' parameter allows us to set the distribution of the\n",
    "# randomized weights that the layer is initialized with.\n",
    "model.add(Dense(64, input_dim=10, kernel_initializer=\"uniform\"))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, kernel_initializer=\"uniform\"))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(46, kernel_initializer=\"uniform\"))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Momentum: how much the weights are adjusted in response to the current gradient.\n",
    "# Nesterov momentum: weights are adjusted by gradient descent, but gradient is also corrected\n",
    "# after each step by examining the direction of the gradient at the new location.\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=16)\n",
    "score = model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Mmm...not a great job!  Although with 46 classes it's okay, but we can do better.  We'll return!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Merge Layers\n",
    "- Merge multiple layer sequences into a single layer\n",
    "- A number of options for merging outputs: `concat`, `sum`, `ave`, etc\n",
    "- Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T22:26:54.837753Z",
     "start_time": "2019-05-31T22:26:54.728898Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "left_branch_input = keras.layers.Input(shape=(784,))\n",
    "x1 = keras.layers.Dense(32, )(left_branch_input)\n",
    "\n",
    "right_branch_input = keras.layers.Input(shape=(784,))\n",
    "x2 = keras.layers.Dense(32)(right_branch_input)\n",
    "\n",
    "merged = keras.layers.concatenate([x1, x2])\n",
    "main_output = keras.layers.Dense(10, activation='sigmoid')(merged)\n",
    "\n",
    "model = keras.models.Model(inputs=[left_branch_input, right_branch_input], outputs=[main_output])\n",
    "\n",
    "# This is what the compile and training looks like\n",
    "# Note that to get this to run you will need to provide two sets of inputs, x_left and x_right\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## And More...\n",
    "\n",
    "Check out the [Keras Documentation on Layers](https://keras.io/layers/about-keras-layers/) to see what your options are. Keras provides lots (and lots, and lots) of options for ways to connect nodes between layers, for transforming or normalizing data, for specifying activation functions, and so on. If you're feeling brave, [you can also write your own layers](https://keras.io/layers/writing-your-own-keras-layers/).\n",
    "\n",
    "In the next notebook we'll take a look at Embeddings, Convolutional layers, and several flavors of Recurrent layers."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "livereveal": {
   "height": "100%",
   "margin": 0,
   "maxScale": 1,
   "minScale": 1,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky",
   "transition": "zoom",
   "width": "100%"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "369px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "457px",
    "left": "0px",
    "right": "968px",
    "top": "130px",
    "width": "244.172px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
