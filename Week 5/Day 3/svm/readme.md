# Sample Lesson Plan
- (60m) [SVMs](SVM_Solutions.ipynb)
- (30m) [big SVMs](big_SVM_Solutions.ipynb)

# Learning Objectives

Students can

- Write, in pseudocode, the SVM prediction function given weights or example coefficients.
- Kernels
  - Explain what the kernel trick is and why it is important for SVM efficiency and improving the kinds of functions SVMs can learn.
  - Identify the right kernel for different classification problems.
  - Tune hyperparameters for common kernels.
- Support Vectors
  - Explain what support vectors are.
  - Find the support vectors for a trained SVM.
- Soft Margin
  - Explain what is meant by soft margin.
  - Tune the `c` hyperparameter for different classification problems.
- Big Data
  - Use kernel approximation and SGD to train an SVM on big data.

# Depends On

[Model Linearity](https://github.com/thisismetis/dscurriculum_gamma/tree/master/curriculum/project-03/model-linearity)

# Additional Resources