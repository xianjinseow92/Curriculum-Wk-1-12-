{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Set 1:  MTA Turnstile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.1\n",
    "\n",
    "- Open up a new Jupyter notebook\n",
    "- Download a few MTA turnstile data files\n",
    "- Open up a file, use csv reader to read it, make a python dict where\n",
    "  there is a key for each (C/A, UNIT, SCP, STATION). These are the\n",
    "  first four columns. The value for this key should be a list of\n",
    "  lists. Each list in the list is the rest of the columns in a\n",
    "  row. For example, one key-value pair should look like\n",
    "\n",
    "\n",
    "{    ('A002','R051','02-00-00','LEXINGTON AVE'):\n",
    "[\n",
    "['NQR456', 'BMT', '01/03/2015', '03:00:00', 'REGULAR', '0004945474', '0001675324'],\n",
    "['NQR456', 'BMT', '01/03/2015', '07:00:00', 'REGULAR', '0004945478', '0001675333'],\n",
    "['NQR456', 'BMT', '01/03/2015', '11:00:00', 'REGULAR', '0004945515', '0001675364'],\n",
    "...\n",
    "]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: http://web.mta.info/developers/turnstile.html\n",
    "def get_data(week_nums):\n",
    "    url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\"\n",
    "    dfs = []\n",
    "    for week_num in week_nums:\n",
    "        file_url = url.format(week_num)\n",
    "        dfs.append(pd.read_csv(file_url))\n",
    "    return pd.concat(dfs)\n",
    "        \n",
    "week_nums = [160903, 160910, 160917]\n",
    "turnstiles_df = get_data(week_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_df.columns = [column.strip() for column in turnstiles_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three weeks of Data\n",
    "turnstiles_df.DATE.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Exercise 1.2\n",
    "\n",
    "- Let's turn this into a time series.\n",
    "\n",
    " For each key (basically the control area, unit, device address and\n",
    " station of a specific turnstile), have a list again, but let the list\n",
    " be comprised of just the point in time and the count of entries.\n",
    "\n",
    "This basically means keeping only the date, time, and entries fields\n",
    "in each list. You can convert the date and time into datetime objects\n",
    "-- That is a python class that represents a point in time. You can\n",
    "combine the date and time fields into a string and use the\n",
    "[dateutil](https://labix.org/python-dateutil) module to convert it\n",
    "into a datetime object. For an example check\n",
    "[this StackOverflow question](http://stackoverflow.com/questions/23385003/attributeerror-when-using-import-dateutil-and-dateutil-parser-parse-but-no).\n",
    "\n",
    "Your new dict should look something like\n",
    "\n",
    "{    ('A002','R051','02-00-00','LEXINGTON AVE'):\n",
    "[\n",
    "[datetime.datetime(2013, 3, 2, 3, 0), 3788],\n",
    "[datetime.datetime(2013, 3, 2, 7, 0), 2585],\n",
    "[datetime.datetime(2013, 3, 2, 12, 0), 10653],\n",
    "[datetime.datetime(2013, 3, 2, 17, 0), 11016],\n",
    "[datetime.datetime(2013, 3, 2, 23, 0), 10666],\n",
    "[datetime.datetime(2013, 3, 3, 3, 0), 10814],\n",
    "[datetime.datetime(2013, 3, 3, 7, 0), 10229],\n",
    "...\n",
    "],\n",
    "....\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((turnstiles_df[\"C/A\"] == \"A002\") & \n",
    "        (turnstiles_df[\"UNIT\"] == \"R051\") & \n",
    "        (turnstiles_df[\"SCP\"] == \"02-00-00\") & \n",
    "        (turnstiles_df[\"STATION\"] == \"59 ST\"))\n",
    "turnstiles_df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the date and time fields into a single datetime column\n",
    "turnstiles_df[\"DATE_TIME\"] = pd.to_datetime(turnstiles_df.DATE + \" \" + turnstiles_df.TIME, format=\"%m/%d/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((turnstiles_df[\"C/A\"] == \"R626\") & \n",
    "(turnstiles_df[\"UNIT\"] == \"R062\") & \n",
    "(turnstiles_df[\"SCP\"] == \"00-00-00\") & \n",
    "(turnstiles_df[\"STATION\"] == \"CROWN HTS-UTICA\"))\n",
    "turnstiles_df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turnstiles_df = .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"]).ENTRIES.count().reset_index().sort_values(\"ENTRIES\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check to verify that \"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\" is unique\n",
    "(turnstiles_df\n",
    " .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    " .sort_values(\"ENTRIES\", ascending=False)).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On 9/16, we seem to have two entries for same time.  Let's take a look\n",
    "mask = ((turnstiles_df[\"C/A\"] == \"R504\") & \n",
    "(turnstiles_df[\"UNIT\"] == \"R276\") & \n",
    "(turnstiles_df[\"SCP\"] == \"00-00-01\") & \n",
    "(turnstiles_df[\"STATION\"] == \"VERNON-JACKSON\") &\n",
    "(turnstiles_df[\"DATE_TIME\"].dt.date == datetime.datetime(2016, 9, 16).date()))\n",
    "turnstiles_df[mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looks to be a incorrect AUD entry.  May be we should just select the Regular One."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_df.DESC.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since we are only interested in Entries, we might be OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the duplicate entry\n",
    "turnstiles_df.sort_values([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"], inplace=True, ascending=False)\n",
    "turnstiles_df.drop_duplicates(subset=[\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check to verify that \"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\" is unique\n",
    "(turnstiles_df\n",
    " .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    " .sort_values(\"ENTRIES\", ascending=False)).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No more duplicate Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Exits and Desc Column.  To prevent errors in multiple run of cell, errors on drop is ignored\n",
    "turnstiles_df = turnstiles_df.drop([\"EXITS\", \"DESC\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.3\n",
    "\n",
    "- These counts are for every n hours. (What is n?) We want total daily\n",
    "  entries.\n",
    "\n",
    "Now make it that we again have the same keys, but now we have a single\n",
    "value for a single day, which is the total number of passengers that\n",
    "entered through this turnstile on this day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_daily = turnstiles_df.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE\"]).ENTRIES.first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_daily[[\"PREV_DATE\", \"PREV_ENTRIES\"]] = (turnstiles_daily\n",
    "                                                       .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATE\", \"ENTRIES\"]\n",
    "                                                       .transform(lambda grp: grp.shift(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_daily.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows for last date\n",
    "turnstiles_daily.dropna(subset=[\"PREV_DATE\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_daily[turnstiles_daily[\"ENTRIES\"] < turnstiles_daily[\"PREV_ENTRIES\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the deal with counter being in reverse\n",
    "mask = ((turnstiles_df[\"C/A\"] == \"A011\") & \n",
    "(turnstiles_df[\"UNIT\"] == \"R080\") & \n",
    "(turnstiles_df[\"SCP\"] == \"01-00-00\") & \n",
    "(turnstiles_df[\"STATION\"] == \"57 ST-7 AV\") &\n",
    "(turnstiles_df[\"DATE_TIME\"].dt.date == datetime.datetime(2016, 8, 27).date()))\n",
    "turnstiles_df[mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Counter working in Reverse??? - WHHHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many stations have this problem\n",
    "\n",
    "(turnstiles_daily[turnstiles_daily[\"ENTRIES\"] < turnstiles_daily[\"PREV_ENTRIES\"]]\n",
    "    .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])\n",
    "     .size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_counts(row, max_counter):\n",
    "    counter = row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"]\n",
    "    if counter < 0:\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "        return 0\n",
    "    return counter\n",
    "\n",
    "# If counter is > 1Million, then the counter might have been reset.  \n",
    "# Just set it to zero as different counters have different cycle limits\n",
    "_ = turnstiles_daily.apply(get_daily_counts, axis=1, max_counter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_counts(row, max_counter):\n",
    "    counter = row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"]\n",
    "    if counter < 0:\n",
    "        # May be counter is reversed?\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "        counter = min(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "    if counter > max_counter:\n",
    "        # Check it again to make sure we are not giving a counter that's too big\n",
    "        return 0\n",
    "    return counter\n",
    "\n",
    "# If counter is > 1Million, then the counter might have been reset.  \n",
    "# Just set it to zero as different counters have different cycle limits\n",
    "turnstiles_daily[\"DAILY_ENTRIES\"] = turnstiles_daily.apply(get_daily_counts, axis=1, max_counter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnstiles_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that we got same results via the non-pandas version."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
