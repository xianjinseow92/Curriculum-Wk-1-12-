# Sample Lesson Plan

* (30 min) [Intro to Spark](../spark-intro/intro_to_spark.pptx)
* (30 min) [Intro to Spark API](../pyspark-lab/intro_to_spark_api.ipynb)
* (20 min) [Word Count Exercise](../pyspark-lab/word_count_exercise.ipynb)
* (20 min) [Spark SQL Exercise](../pyspark-lab/airline_delays_sparksql_exercise.ipynb)
* (45-60 min) [ML with Spark](../pyspark-lab/machine_learning_with_spark.ipynb)

Optionals if there's time:

* (20 min) [Spam Classification with
Spark](../pyspark-lab/spam_classification_with_spark.ipynb)
* (20 min) [Recommendations in Spark](../pyspark-lab/spark_recommendation_systems.ipynb)

Note that there are 2 days for Spark. You can spread this content across both days, focusing on
theory/API the first day and getting as far as possible into the exercises. Then on the second
day revisiting the API and covering as much of the other material as possible.


# Learning Objectives

At the end of this lesson the students should:

* Understand how Spark differs from MapReduce/Hadoop
* Know what a DAG is and why it makes Spark go
* Know what an RDD is
* Be familiar with the Spark DataFrame API
* Know how to use SparkSQL
* Know how Spark ML works
* Know what Vector Assembler and Pipeline are and why they're important
* Have a sense of how flexible Spark is in dealing with tabular and text data

# Depends On

# Additional Resources

Setting up a Spark Cluster on Amazon EMR:
[walkthrough](setting_up_EMR_spark.md)

Reading and writing directly to S3 with Spark:
[Example](linking_spark_to_s3.ipynb)