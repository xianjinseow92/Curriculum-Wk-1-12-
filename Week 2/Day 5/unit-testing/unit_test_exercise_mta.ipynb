{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import sys\n",
    "libraries = (('Matplotlib', matplotlib), ('Numpy', np), ('Pandas', pd))\n",
    "\n",
    "print(\"Python Version:\", sys.version, '\\n')\n",
    "for lib in libraries:\n",
    "    print('{0} Version: {1}'.format(lib[0], lib[1].__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T00:23:50.186110Z",
     "start_time": "2019-02-07T00:23:38.012149Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!wget -nc -P data https://s3.amazonaws.com/gamma-datasets/P2/mta_turnstile_160903.txt https://s3.amazonaws.com/gamma-datasets/P2/mta_turnstile_160910.txt https://s3.amazonaws.com/gamma-datasets/P2/mta_turnstile_160917.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: UnitTesting with Real Data\n",
    "\n",
    "We're going to revisit the MTA data and get started with building some unit tests together. I'm providing the tests in the TestDataLoader class, you need to write a function that \n",
    "* takes in a list of week IDs as input\n",
    "* loads the dataframe corresponding to those week IDs (check out the data folder) and combines them\n",
    "* returns the single dataframe\n",
    "\n",
    "You should be able to pass all of the tests. Note that some of them require some minimal cleaning already before returning things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_into_dataframe(week_ids):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestDataLoader(unittest.TestCase):\n",
    "    \n",
    "    def test_fails_without_file_list(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            load_data_into_dataframe()\n",
    "        with self.assertRaises(TypeError):\n",
    "            load_data_into_dataframe(160903)\n",
    "    \n",
    "    def test_output_type(self):\n",
    "        self.assertIs(type(load_data_into_dataframe([160903])), type(pd.DataFrame()))\n",
    "        \n",
    "    def test_column_names(self):\n",
    "        df = load_data_into_dataframe([160903])\n",
    "        bool_cols = (df.columns == ['C/A', 'UNIT', 'SCP', 'STATION', 'LINENAME', 'DIVISION', 'DATE', 'TIME',\n",
    "       'DESC', 'ENTRIES','EXITS'])\n",
    "        self.assertTrue(bool_cols.all())\n",
    "        \n",
    "    def test_multiple_files_of_data(self):\n",
    "        df = load_data_into_dataframe([160903,160910])\n",
    "        self.assertIs(type(df), type(pd.DataFrame()))\n",
    "\n",
    "unittest.main(TestDataLoader(), argv=['first-arg-is-ignored'], exit=False)\n",
    "# Note that this time I added the name of the testing class as an arg so it only runs that\n",
    "# tester instead of all the possible testers currently defined!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Writing the function and the Tests\n",
    "\n",
    "Now your goal is to write both the functions and the tests. The goal here is that we're going to write a function to clean and prepare our data. The function should:\n",
    "\n",
    "* Take in a dataframe that already contains a Date and Time column\n",
    "* Create a DATE_TIME column using the DATE and TIME columns\n",
    "* Make sure that each grouping of [\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"] is unique\n",
    "\n",
    "For tests, you should write tests to check the output types of columns, check that the uniqueness values are being handled properly, as well as any other tests you can think of. \n",
    "\n",
    "In ~15 minutes, we'll have someone come up and present both their code and their tests and other folks can chime in about the types of tests they've written as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data_into_dataframe([160917])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU NEED TO CODE THIS!\n",
    "class TestDataCleaner(unittest.TestCase):\n",
    "    \n",
    "    pass\n",
    "\n",
    "unittest.main(TestDataCleaner(), argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metis",
   "language": "python",
   "name": "metis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
