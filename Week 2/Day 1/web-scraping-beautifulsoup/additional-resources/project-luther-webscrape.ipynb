{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEBSCRAPING CAVEATS\n",
    "\n",
    "The code contained in this brief tutorial is intended for illustration purposes only. It was not implemented with code design or optimization in mind. It merely shows how to scrape data from various sources using Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib2 import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SOURCE #1 - Sports Stats\n",
    "\n",
    "The website [sports-reference.com](http://www.sports-reference.com/) includes statistics for the MLB, NBA, NFL, NHL, CFB, CBB, and the Olympics. As an example, this tutorial will show how to scrape Chicago Blackhawk player statistics for the 2015-2016 season located [here](http://www.hockey-reference.com/teams/CHI/2016.html) and convert it to a pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DATA\n",
    "url = \"http://www.hockey-reference.com/teams/CHI/2016.html\"\n",
    "html = urlopen(url)\n",
    "\n",
    "# PRE-PROCESS\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "table = soup.findAll(\"table\", class_=\"sortable stats_table\")\n",
    "scoring = table[2]  # subset to just scoring table\n",
    "column_headers = [th.getText() for th in \n",
    "                  scoring.findAll('tr')[1].findAll('th')][1:]  # drop 'Rk'\n",
    "data_rows = scoring.findAll('tr')[2:]  # skip the first 2 header rows\n",
    "player_data = [[td.getText() for td in data_rows[i].findAll('td')]\n",
    "               for i in range(len(data_rows))]\n",
    "\n",
    "# CREATE DF\n",
    "df = pd.DataFrame(player_data, columns=column_headers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SOURCE #2 - Beer\n",
    "\n",
    "The website [http://hbd.org/ensmingr/](http://hbd.org/ensmingr/) gives the percent alcohol, number of calories, specific gravity before (OG) and after (FG) fermentation, and apparent attenuation for ~1000 commercial beers from ~100 breweries, as of 1999. As an example, this tutorial will show how to scrape data for Grant's Brewery located [here](http://hbd.org/ensmingr/grants.html) and convert it to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DATA\n",
    "url2 = \"http://hbd.org/ensmingr/grants.html\"\n",
    "html2 = urlopen(url2)\n",
    "\n",
    "# PRE-PROCESS\n",
    "soup2 = BeautifulSoup(html2, 'lxml')\n",
    "column_headers = ['Company and Product', 'Location', 'Percent_Alcohol', 'Calories_Per_12', 'OG', 'FG', 'AA', 'Notes']\n",
    "data_rows2 = soup2.findAll('tr')[2:]  # skip the first 2 header rows\n",
    "beer_data = [[td.getText() for td in data_rows2[i].findAll('td')]\n",
    "             for i in range(len(data_rows2))]\n",
    "beer_data = [[unicodedata.normalize('NFKD', beer_data[i][j]).encode('ascii','ignore') for j in range(8)] for i in range(len(beer_data))]\n",
    "\n",
    "# CREATE DF\n",
    "df2 = pd.DataFrame(beer_data, columns=column_headers).replace({'\\r\\n': ''}, regex=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WITH PANDAS (much easier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grants = pd.read_html(url2, header=0)[0]\n",
    "grants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SOURCE #3 - Wine\n",
    "\n",
    "The website [http://www.wineinstitute.org/resources/pressroom/07082016](http://www.wineinstitute.org/resources/pressroom/07082016) gives wine sales in the U.S. and California.  As an example, this tutorial will show how to scrape wine sales data (in millions of 9-liter cases - from California, other states, and foreign producers entering U.S. distribution) and convert it to a pandas dataframe.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET DATA\n",
    "url3 = \"http://www.wineinstitute.org/resources/pressroom/07082016\"\n",
    "html3 = urlopen(url3)\n",
    "\n",
    "# PRE-PROCESS\n",
    "soup3 = BeautifulSoup(html3, \"lxml\")\n",
    "table3 = soup3.findAll(\"table\")\n",
    "sales = table3[1]  # subset to just wine sales table\n",
    "column_headers3 = ['Year', 'Table', 'Dessert', 'Sparkling', 'Total_Wine', 'Total_Retail_Value']\n",
    "data_rows3 = sales.findAll('tr')[2:]  # skip the first 2 header rows\n",
    "wine_data = [[td.getText() for td in data_rows3[i].findAll('td')]\n",
    "             for i in range(len(data_rows3))]\n",
    "\n",
    "# CREATE DF\n",
    "df3 = pd.DataFrame(wine_data, columns=column_headers3)\n",
    "df3.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
